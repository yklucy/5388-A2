{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b41e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import river\n",
    "\n",
    "from river import compose\n",
    "from river import preprocessing\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import evaluate\n",
    "from river import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from kafka import KafkaConsumer\n",
    "from river import multiclass\n",
    "import skmultiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "071bc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the print content to file \n",
    "f1 = open(\"./2-2-6 predictive scores for an adaptive model with initial data.log\",'w+')\n",
    "f2 = open(\"./2-2-6 predictive scores for an adaptive mode with kafka data.log\",'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "24b98c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ get data from sklearn ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# read from sklearn\n",
    "\n",
    "\n",
    "data_aftcat = pd.read_csv(r\"./2-2-1 5388 data_aftcat.csv\")\n",
    "data_y = pd.read_csv(r\"./2-2-1 5388 data_aftcat class.csv\")\n",
    "data = pd.read_csv(r\"./2-2-1 5388 data_aftcat_full.csv\") # class, source(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a2ab339",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_col = data.columns\n",
    "d_aftcat_col = data_aftcat.columns\n",
    "y_col = data_y.columns\n",
    "# change from pd.DataFrame to np.array\n",
    "data = np.array(data)\n",
    "data_aftcat = np.array(data_aftcat)\n",
    "data_y = np.array(data_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d63724",
   "metadata": {},
   "source": [
    "# train an adaptive model with initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "723f9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^ train a model using river ^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# train an adaptive model and prediction\n",
    "mm = river.preprocessing.StandardScaler()\n",
    "#selector = river.feature_selection.VarianceThreshold()\n",
    "#model_adaptive = tree.HoeffdingAdaptiveTreeClassifier(grace_period=100,split_confidence=1e-5,leaf_prediction='nb',nb_threshold=10,seed=0)\n",
    "model_adaptive = neighbors.KNNClassifier() # window_size (int) â€“ defaults to 1000\n",
    "#model = compose.Pipeline(mm,selector,model_adaptive)\n",
    "#model = compose.Pipeline(mm,model_adaptive)\n",
    "#model = river.imblearn.RandomOverSampler((mm | selector| model_adaptive),desired_dist={False: 0.5, True: 0.5})\n",
    "ovr = multiclass.OneVsRestClassifier(model_adaptive)\n",
    "model = mm | ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "668ef81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = metrics.Accuracy()\n",
    "metric_classr = metrics.ClassificationReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61e85280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = prediction score for an active model with initial data = = = = = \n"
     ]
    }
   ],
   "source": [
    "print(\"= = = = = = prediction score for an active model with initial data = = = = = \")\n",
    "print(\"= = = = = = prediction score for an active model with initial data = = = = = \",file=f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "48441bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_acc: Accuracy: 97.32%\n",
      "i: 25284\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for xi, yi in zip(data_aftcat,data_y):\n",
    "    xi = dict(zip(d_aftcat_col, xi))   # transfor array to dict\n",
    "    yi = yi[0]\n",
    "    yi_pred = model.predict_one(xi)\n",
    "    metric_acc = metric_acc.update(yi,yi_pred)\n",
    "    #metric_classr = metric_classr.update(yi,yi_pred)\n",
    "    model = model.learn_one(xi, yi)\n",
    "    i=i+1\n",
    "\n",
    "print(\"metric_acc:\",metric_acc)\n",
    "#print(\"metric_classr:\",metric_classr)\n",
    "print(\"i:\",i)\n",
    "\n",
    "print(\"metric_acc:\",metric_acc,file=f1)\n",
    "#print(\"metric_classr\",metric_classr,file=f1)\n",
    "print(\"i:\",i,file=f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3dfeeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for xi, yi in zip(data_aftcat,data_y):\n",
    "    xi = dict(zip(d_aftcat_col, xi))   # transfor array to dict\n",
    "    yi = int(yi[0])\n",
    "    #print(\"yi:\",yi)\n",
    "    yi_pred = int(model.predict_one(xi))\n",
    "    #print(\"yi_pred\",yi_pred)\n",
    "    #metric_acc = metric_acc.update(yi,yi_pred)\n",
    "    metric_classr = metric_classr.update(yi,yi_pred)\n",
    "    model = model.learn_one(xi, yi)\n",
    "    #break\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ee9aefa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Precision   Recall   F1      Support  \n",
       "                                                 \n",
       "       0       0.998    0.996   0.997     21962  \n",
       "       1       0.000    0.000   0.000        18  \n",
       "       2       0.875    0.987   0.928       377  \n",
       "       3       0.746    0.645   0.692         2  \n",
       "       4       0.291    0.300   0.296       213  \n",
       "       5       0.572    0.700   0.630       446  \n",
       "       6       0.188    0.031   0.054        96  \n",
       "       7       0.657    0.512   0.575        86  \n",
       "       8       0.864    0.376   0.524       101  \n",
       "       9       0.939    0.993   0.965      1774  \n",
       "      10       0.000    0.000   0.000        11  \n",
       "                                                 \n",
       "   Macro       0.557    0.504   0.515            \n",
       "   Micro       0.973    0.973   0.973            \n",
       "Weighted       0.971    0.973   0.971            \n",
       "\n",
       "                 97.3% accuracy                  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_classr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "107a2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for xi, yi in zip(data_aftcat,data_y):\n",
    "    xi = dict(zip(d_aftcat_col, xi))   # transfor array to dict\n",
    "    yi = yi[0]\n",
    "    #print(\"yi:\",yi)\n",
    "    yi_pred = model.predict_one(xi)\n",
    "    \n",
    "    if yi != None:\n",
    "        if yi_pred != None:\n",
    "            #print(\"yi_pred\",yi_pred)\n",
    "            #metric_acc = metric_acc.update(yi,yi_pred)\n",
    "            metric_classr = metric_classr.update(yi,yi_pred)\n",
    "            model = model.learn_one(xi, yi)\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "55f6746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_classr:            Precision   Recall   F1      Support  \n",
      "                                                 \n",
      "       0       0.998    0.996   0.997     43924  \n",
      "       1       0.000    0.000   0.000        36  \n",
      "       2       0.874    0.987   0.927       754  \n",
      "       3       0.744    0.645   0.691         4  \n",
      "       4       0.294    0.303   0.298       426  \n",
      "       5       0.574    0.702   0.631       892  \n",
      "       6       0.188    0.031   0.054       192  \n",
      "       7       0.654    0.506   0.570       172  \n",
      "       8       0.862    0.371   0.519       202  \n",
      "       9       0.939    0.993   0.965      3548  \n",
      "      10       0.000    0.000   0.000        22  \n",
      "                                                 \n",
      "   Macro       0.557    0.503   0.514            \n",
      "   Micro       0.973    0.973   0.973            \n",
      "Weighted       0.971    0.973   0.971            \n",
      "\n",
      "                 97.3% accuracy                  \n",
      "i: 25284\n"
     ]
    }
   ],
   "source": [
    "print(\"metric_classr:\",metric_classr)\n",
    "print(\"i:\",i)\n",
    "print(\"metric_classr\",metric_classr,file=f1)\n",
    "print(\"i:\",i,file=f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf41f37",
   "metadata": {},
   "source": [
    "# train an adaptive model with kafka data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4f640952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ read kafka data and detect concept drift^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# instantiate the KafkaConsumer Class using the arguments mentioned.\n",
    "# do not change any arguments other than the first positional argument.\n",
    "consumer = KafkaConsumer(\n",
    "    'task2',   # change this to \"task2\" for the IOT Botnet Detection  ---- important ----\n",
    "    bootstrap_servers=\"34.130.121.39:9092\",\n",
    "    sasl_plain_username=\"student\",\n",
    "    sasl_plain_password=\"uottawa\",\n",
    "    security_protocol=\"SASL_PLAINTEXT\",\n",
    "    sasl_mechanism=\"PLAIN\",\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3e564d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc_kafka = metrics.Accuracy\n",
    "metric_cr_kafka= metrics.ClassificationReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "edb0e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ function: map Class to 0 - 10^^^^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "def Class_map(d_c):\n",
    "    if (d_c == 'BENIGN'):        \n",
    "        y = 0\n",
    "    else:\n",
    "        if(d_c == 'mirai_udp_attack'):\n",
    "            y = 1\n",
    "        else:\n",
    "            if(d_c == 'mirai_ack_attack'):\n",
    "                y = 2\n",
    "            else:\n",
    "                if(d_c == 'gafgyt_scan_attack'):\n",
    "                    y = 3\n",
    "                else:\n",
    "                    if(d_c == 'mirai_scan_attack'):\n",
    "                        y = 4\n",
    "                    else:\n",
    "                        if(d_c == 'gafgyt_tcp_attack'):\n",
    "                            y = 5\n",
    "                        else:\n",
    "                            if(d_c == 'gafgyt_udp_attack'):\n",
    "                                y = 6\n",
    "                            else:\n",
    "                                if(d_c == 'gafgyt_junk_attack'):\n",
    "                                    y = 7\n",
    "                                else:\n",
    "                                    if(d_c == 'gafgyt_combo_attack'):\n",
    "                                        y = 8\n",
    "                                    else:\n",
    "                                        if(d_c == 'mirai_syn_attack'):\n",
    "                                            y = 9\n",
    "                                        else:\n",
    "                                            if(d_c == 'mirai_udpplain_attack'):\n",
    "                                                y = 10\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9cf7c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ function: map Source to OneHotEncoder^^^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "def source_map(d_s):\n",
    "    sr_dict = {'x0_0': 0.0, 'x0_1': 0.0, 'x0_2': 0.0, 'x0_3': 0.0, 'x0_4': 0.0, 'x0_5': 0.0, 'x0_6': 0.0, 'x0_7': 0.0, 'x0_8': 0.0}\n",
    "    if(d_s == 'Provision PT 838 Security Camera'):\n",
    "        sr_dict['x0_0'] = 1.0\n",
    "    else:\n",
    "        if(d_s == 'Provision PT 737E Security Camera'):\n",
    "            sr_dict['x0_1'] = 1.0\n",
    "        else:\n",
    "            if(d_s == 'Samsung SNH 1011 N Webcam'):\n",
    "                sr_dict['x0_2'] = 1.0\n",
    "            else:\n",
    "                if(d_s == 'SimpleHome XCS7 1002 WHT Security Camera'):\n",
    "                    sr_dict['x0_3'] = 1.0\n",
    "                else:\n",
    "                    if(d_s == 'Philips B120N10 Baby Monitor'):\n",
    "                        sr_dict['x0_4'] = 1.0\n",
    "                    else:\n",
    "                        if(d_s == 'SimpleHome XCS7 1003 WHT Security Camera'):\n",
    "                            sr_dict['x0_5'] = 1.0\n",
    "                        else:\n",
    "                            if(d_s == 'Ennio Doorbell'):\n",
    "                                sr_dict['x0_6'] = 1.0\n",
    "                            else:\n",
    "                                if(d_s == 'Danmini Doorbell'):\n",
    "                                    sr_dict['x0_7'] = 1.0\n",
    "                                else:\n",
    "                                    if(d_s == 'Ecobee Thermostat'):\n",
    "                                        sr_dict['x0_8'] = 1.0\n",
    "    return sr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f37e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected at index 1007\n",
      "Drift detected at index 2281\n",
      "Drift detected at index 3288\n",
      "Drift detected at index 4371\n",
      "Drift detected at index 6199\n",
      "Drift detected at index 7869\n",
      "Drift detected at index 9518\n",
      "Drift detected at index 11191\n",
      "Drift detected at index 12766\n",
      "Drift detected at index 14737\n",
      "Drift detected at index 15877\n",
      "Drift detected at index 17259\n",
      "Drift detected at index 18755\n",
      "Drift detected at index 20205\n",
      "Drift detected at index 21573\n",
      "Drift detected at index 25158\n",
      "Drift detected at index 26686\n",
      "Drift detected at index 27800\n",
      "Drift detected at index 29040\n",
      "Drift detected at index 30057\n",
      "Drift detected at index 31078\n",
      "Drift detected at index 32937\n",
      "Drift detected at index 33963\n",
      "Drift detected at index 35248\n",
      "Drift detected at index 36316\n",
      "Drift detected at index 37895\n",
      "Drift detected at index 39367\n",
      "Drift detected at index 40845\n",
      "Drift detected at index 41994\n",
      "Drift detected at index 43111\n",
      "Drift detected at index 44114\n",
      "Drift detected at index 45742\n",
      "Drift detected at index 46763\n",
      "Drift detected at index 47866\n",
      "Drift detected at index 49438\n",
      "Drift detected at index 50527\n",
      "Drift detected at index 51567\n",
      "Drift detected at index 53015\n",
      "Drift detected at index 54040\n",
      "Drift detected at index 55935\n",
      "Drift detected at index 57158\n",
      "Drift detected at index 58759\n",
      "Drift detected at index 59920\n",
      "Drift detected at index 61519\n",
      "Drift detected at index 63441\n",
      "Drift detected at index 64769\n",
      "Drift detected at index 65905\n",
      "Drift detected at index 67752\n",
      "Drift detected at index 68939\n",
      "Drift detected at index 70249\n",
      "Drift detected at index 71868\n",
      "Drift detected at index 73093\n",
      "Drift detected at index 74850\n",
      "Drift detected at index 75903\n",
      "Drift detected at index 76943\n",
      "Drift detected at index 78114\n",
      "Drift detected at index 79158\n",
      "Drift detected at index 80419\n",
      "Drift detected at index 83039\n",
      "Drift detected at index 85981\n",
      "Drift detected at index 87033\n",
      "Drift detected at index 88503\n",
      "Drift detected at index 90078\n",
      "Drift detected at index 91131\n",
      "Drift detected at index 92490\n",
      "Drift detected at index 93764\n",
      "Drift detected at index 94829\n",
      "Drift detected at index 96550\n",
      "Drift detected at index 99037\n"
     ]
    }
   ],
   "source": [
    "# Data Stream flowing in. - - - Dict()\n",
    "i = 0\n",
    "# concept drift detection\n",
    "kswin = river.drift.KSWIN(window_size = 1000)\n",
    "drifts_ksw = []\n",
    "nan=0\n",
    "inf=0\n",
    "for message in consumer:\n",
    "    #print(message)\n",
    "    tmp_data=eval(message.value.decode(errors='ignore'))   #dict()\n",
    "    dict_y = Class_map(tmp_data['Class'])\n",
    "    dict_source = source_map(tmp_data['Source'])\n",
    "    del tmp_data['Class']\n",
    "    del tmp_data['Source']\n",
    "    dict_data = dict(tmp_data,**dict_source)\n",
    "    #print(\"items:\",tmp_data.items())\n",
    "    #print(\"values:\",tmp_data.values())\n",
    "\n",
    "    # prediction and train an adaptive model\n",
    "    yi_pred = model.predict_one(dict_data)  # make a prediction\n",
    "    if dict_y != None:\n",
    "        if yi_pred != None:\n",
    "            #metric_acc_kafka = metric_acc_kafka.update(dict_y,yi_pred)\n",
    "            metric_cr_kafka = metric_cr_kafka.update(dict_y,yi_pred)\n",
    "            model = model.learn_one(dict_data,dict_y) # make the model learn\n",
    "\n",
    "    # concept drift detection\n",
    "    in_drift, in_warning = kswin.update(message.value)\n",
    "    if in_drift:\n",
    "        print(f'Drift detected at index {i}')\n",
    "        print(f'Drift detected at index {i}',file=f2)\n",
    "        drifts_ksw.append(i)\n",
    "        kswin.reset()   # As a best practice, we reset the detector   \n",
    "\n",
    "    if i == 100000:\n",
    "       break       \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "05a9150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_cr_kafka \n",
      "            Precision   Recall   F1      Support  \n",
      "                                                 \n",
      "       0       0.998    0.996   0.997     86826  \n",
      "       1       0.945    0.990   0.967      6956  \n",
      "       2       0.067    0.006   0.011        32  \n",
      "       3       0.744    0.639   0.688       793  \n",
      "       4       0.597    0.534   0.563       399  \n",
      "       5       0.302    0.308   0.305       883  \n",
      "       6       0.564    0.692   0.621       168  \n",
      "       7       0.874    0.981   0.925      1589  \n",
      "       8       0.200    0.020   0.037        49  \n",
      "       9       0.732    0.363   0.485       452  \n",
      "      10       1.000    0.036   0.069        56  \n",
      "                                                 \n",
      "   Macro       0.638    0.506   0.515            \n",
      "   Micro       0.973    0.973   0.973            \n",
      "Weighted       0.971    0.973   0.971            \n",
      "\n",
      "                 97.3% accuracy                  \n",
      "i: 100000\n"
     ]
    }
   ],
   "source": [
    "#print(\"metric_acc_kafka \\n\",metric_acc_kafka)\n",
    "print(\"metric_cr_kafka \\n\",metric_cr_kafka)\n",
    "print(\"i:\",i)\n",
    "\n",
    "#print(\"metric_cr_kafka \\n\",metric_cr_kafka,file=f2)\n",
    "print(\"metric_acc_kafka \\n\",metric_acc_kafka,file=f2)\n",
    "print(\"i:\",i,file=f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4e090",
   "metadata": {},
   "source": [
    "# Method 2: train an adaptive model using skmultiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "527f2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^ train a model using skmultiflow ^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-30\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "from skmultiflow.lazy import KNNADWINClassifier\n",
    "import skmultiflow\n",
    "f3 = open(\"./2-1-6 predictive scores for an adaptive model using skmultiflow.log\",'w+')\n",
    "\n",
    "data = pd.read_csv(r\"./2-2-1 5388 data_aftcat.csv\")\n",
    "num = len(data.index)\n",
    "\n",
    "# Setup the stream\n",
    "stream = skmultiflow.data.DataStream(data,allow_nan=True)\n",
    "model_knnadw = KNNADWINClassifier(n_neighbors=8, max_window_size=1000, leaf_size=40)\n",
    "\n",
    "# Keep track of sample count and correct prediction count\n",
    "n_samples = 0\n",
    "corrects = 0\n",
    "while n_samples < num:\n",
    "    X, y = stream.next_sample()\n",
    "    #print(\"y:\",y)\n",
    "    pred = model_knnadw.predict(X)\n",
    "    #print(\"pred:\",pred)\n",
    "    if y[0] == pred[0]:\n",
    "        corrects += 1\n",
    "    model_knnadw = model_knnadw.partial_fit(X, y)\n",
    "    n_samples += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8ab08126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNClassifier usage example\n",
      "25284 samples analyzed.\n",
      "KNNADWINClassifier's performance: 0.9703369719981015\n"
     ]
    }
   ],
   "source": [
    "print('KNNClassifier usage example')\n",
    "print(str(n_samples) + ' samples analyzed.')\n",
    "print(\"KNNADWINClassifier's performance: \" + str(corrects/n_samples))\n",
    "\n",
    "print('KNNClassifier usage example',file=f3)\n",
    "print(str(n_samples) + ' samples analyzed.',file=f3)\n",
    "print(\"KNNADWINClassifier's performance: \" + str(corrects/n_samples),file=f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120f94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
