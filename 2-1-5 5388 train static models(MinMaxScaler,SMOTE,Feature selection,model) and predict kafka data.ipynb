{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_infinity(X):\n",
    "    # check for values approaching infinity\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    print(\"the number of infinity:\", X.isna().sum().sum())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_datatypes = {\n",
    "    ' Destination Port': np.int64,\n",
    "    ' Flow Duration': np.int64,\n",
    "    ' Total Fwd Packets': np.int64,\n",
    "    ' Total Backward Packets': np.int64,\n",
    "    'Total Length of Fwd Packets': np.int64,\n",
    "    ' Total Length of Bwd Packets': np.int64,\n",
    "    ' Fwd Packet Length Max': np.int64,\n",
    "    ' Fwd Packet Length Min': np.int64,\n",
    "    ' Fwd Packet Length Mean': np.float64,\n",
    "    ' Fwd Packet Length Std': np.float64,\n",
    "    'Bwd Packet Length Max': np.int64,\n",
    "    ' Bwd Packet Length Min': np.int64,\n",
    "    ' Bwd Packet Length Mean': np.float64,\n",
    "    ' Bwd Packet Length Std': np.float64,\n",
    "    'Flow Bytes/s': np.float64,\n",
    "    ' Flow Packets/s': np.float64,\n",
    "    ' Flow IAT Mean': np.float64,\n",
    "    ' Flow IAT Std': np.float64,\n",
    "    ' Flow IAT Max': np.int64,\n",
    "    ' Flow IAT Min': np.int64,\n",
    "    'Fwd IAT Total': np.int64,\n",
    "    ' Fwd IAT Mean': np.float64,\n",
    "    ' Fwd IAT Std': np.float64,\n",
    "    ' Fwd IAT Max': np.int64, \n",
    "    ' Fwd IAT Min': np.int64,\n",
    "    'Bwd IAT Total': np.int64,\n",
    "    ' Bwd IAT Mean': np.float64,\n",
    "    ' Bwd IAT Std': np.float64,\n",
    "    ' Bwd IAT Max': np.int64,\n",
    "    ' Bwd IAT Min': np.int64,\n",
    "    'Fwd PSH Flags': np.int64,\n",
    "    ' Bwd PSH Flags': np.int64,\n",
    "    ' Fwd URG Flags': np.int64,\n",
    "    ' Bwd URG Flags': np.int64,\n",
    "    ' Fwd Header Length': np.int64,\n",
    "    ' Bwd Header Length': np.int64,\n",
    "    'Fwd Packets/s': np.float64,\n",
    "    ' Bwd Packets/s': np.float64,\n",
    "    ' Min Packet Length': np.int64,\n",
    "    ' Max Packet Length': np.int64,\n",
    "    ' Packet Length Mean': np.float64,\n",
    "    ' Packet Length Std': np.float64,\n",
    "    ' Packet Length Variance': np.float64,\n",
    "    'FIN Flag Count': np.int64,\n",
    "    ' SYN Flag Count': np.int64,\n",
    "    ' RST Flag Count': np.int64,\n",
    "    ' PSH Flag Count': np.int64,\n",
    "    ' ACK Flag Count': np.int64,\n",
    "    ' URG Flag Count': np.int64,\n",
    "    ' CWE Flag Count': np.int64,\n",
    "    ' ECE Flag Count': np.int64,\n",
    "    ' Down/Up Ratio': np.int64,\n",
    "    ' Average Packet Size': np.float64,\n",
    "    ' Avg Fwd Segment Size': np.float64,\n",
    "    ' Avg Bwd Segment Size': np.float64,\n",
    "    ' Fwd Header Length.1': np.int64,\n",
    "    'Fwd Avg Bytes/Bulk': np.int64,\n",
    "    ' Fwd Avg Packets/Bulk': np.int64,\n",
    "    ' Fwd Avg Bulk Rate': np.int64,\n",
    "    ' Bwd Avg Bytes/Bulk': np.int64,\n",
    "    ' Bwd Avg Packets/Bulk': np.int64,\n",
    "    'Bwd Avg Bulk Rate': np.int64,\n",
    "    'Subflow Fwd Packets': np.int64,\n",
    "    ' Subflow Fwd Bytes': np.int64,\n",
    "    ' Subflow Bwd Packets': np.int64,\n",
    "    ' Subflow Bwd Bytes': np.int64,\n",
    "    'Init_Win_bytes_forward': np.int64, \n",
    "    ' Init_Win_bytes_backward': np.int64,\n",
    "    ' act_data_pkt_fwd': np.int64,\n",
    "    ' min_seg_size_forward': np.int64,\n",
    "    'Active Mean': np.float64,\n",
    "    ' Active Std': np.float64,\n",
    "    ' Active Max': np.int64,\n",
    "    ' Active Min': np.int64,\n",
    "    'Idle Mean': np.float64,\n",
    "    ' Idle Std': np.float64,\n",
    "    ' Idle Max': np.int64,\n",
    "    ' Idle Min': np.int64\n",
    "}\n",
    "used_cols = (ids_datatypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from dataset (after feature extraction )\n",
    "# train model: aftcat, CV(Pipeline(imbalanced, MinMaxScaler, selector, model))\n",
    "data_aftcat = pd.read_csv(r\"./2-1 5388 data_aftcat.csv\")\n",
    "data_aftcat_y = pd.read_csv(r\"./2-1 5388 data_aftcat label.csv\")\n",
    "testdata_kafka = pd.read_csv('./2-3 5388 data_kafka_1.csv',dtype=ids_datatypes, usecols=used_cols, low_memory=False)\n",
    "testdata_kafka_label = pd.read_csv(r\"./2-3 5388 data_kafka_1 label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of infinity: 164\n"
     ]
    }
   ],
   "source": [
    "# Step 1: drop features -------------------------------------------------------------\n",
    "list = [' Bwd PSH Flags',' Bwd URG Flags','Fwd Avg Bytes/Bulk',' Fwd Avg Packets/Bulk',' Fwd Avg Bulk Rate',' Bwd Avg Bytes/Bulk',' Bwd Avg Packets/Bulk','Bwd Avg Bulk Rate']\n",
    "testdata_kafka.drop(list, axis=1, inplace=True)\n",
    "\n",
    "# Step 2: drop infinity\n",
    "testdata_kafka = drop_infinity(testdata_kafka)\n",
    "#data = drop_na(testdata_kafka)\n",
    "#print(\"after drop infinity:\", testdata_kafka.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- transform all feature with MinMaxScaler()---------------- \n",
    "mm = MinMaxScaler().fit(data_aftcat)\n",
    "\n",
    "data_aftcat_aftmm = pd.DataFrame(mm.transform(data_aftcat))\n",
    "data_aftcat_aftmm.columns = mm.get_feature_names_out()\n",
    "\n",
    "testdata_kafka_aftmm = pd.DataFrame(mm.transform(testdata_kafka))\n",
    "testdata_kafka_aftmm.columns = mm.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------functions--------------\n",
    "# function score_mean_std: calculate the average and std of scores\n",
    "def score_mean_std(score_sf):\n",
    "    index_a1 = []\n",
    "    index_a2 = []\n",
    "\n",
    "    for i in range(score_sf.shape[1]):\n",
    "        index_a1.append(np.average(score_sf[score_sf.columns[i]]))\n",
    "        index_a2.append(np.std(score_sf[score_sf.columns[i]]))\n",
    "\n",
    "    index_a1 = pd.DataFrame(index_a1, index = score_sf.columns)\n",
    "    index_a2 = pd.DataFrame(index_a2, index = score_sf.columns)\n",
    "    #print(index_a1.T)\n",
    "    #print(index_a2.T)\n",
    "    re = pd.concat([index_a1.T,index_a2.T],axis=0)\n",
    "    re.index = [\"avg\",\"std\"]\n",
    "    #print(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- train predictive model with pipeline: SMOTE(),VarianceThreshold(), cross_validate()--------\n",
    "def train_model(sm, se, model, X, y):\n",
    "    #print(model, \"\\n\")\n",
    "    #pipe_steps = [('smo',sm),('mm',m),('selector',se),('model',model)]\n",
    "    pipe_steps = [('smo',sm),('selector',se),('model',model)]\n",
    "    id_pipeline = imblearn.pipeline.Pipeline(steps=pipe_steps)\n",
    "\n",
    "    # evaluate the pipeline using the crossvalidation technique defined in cv\n",
    "\n",
    "    # ------------------- score ------------------------------------\n",
    "    scoring = {'f1', 'precision', 'accuracy',\n",
    "            'recall', 'roc_auc'}\n",
    "\n",
    "    score_sf = cross_validate(id_pipeline, X, y.values.ravel(),cv=10,scoring=scoring, n_jobs=-1)\n",
    "    score_sf_re = score_mean_std(pd.DataFrame(score_sf))\n",
    "\n",
    "    return score_sf,score_sf_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- prediction with pipeline: SMOTE(),VarianceThreshold(), cross_validate()--------\n",
    "def pred_kafka(se, model, X, y):\n",
    "    #print(model, \"\\n\")\n",
    "    #pipe_steps = [('mm',m),('selector',se),('model',model)]\n",
    "    pipe_steps = [('selector',se),('model',model)]\n",
    "    id_pipeline = sklearn.pipeline.Pipeline(steps=pipe_steps)\n",
    "\n",
    "    # evaluate the pipeline using the crossvalidation technique defined in cv\n",
    "\n",
    "    # ------------------- score ------------------------------------\n",
    "    scoring = {'f1', 'precision', 'accuracy',\n",
    "            'recall', 'roc_auc'}\n",
    "\n",
    "    score_sf = cross_validate(id_pipeline, X, y.values.ravel(),cv=10,scoring=scoring, n_jobs=-1)\n",
    "    score_sf_re = score_mean_std(pd.DataFrame(score_sf))\n",
    "\n",
    "    return score_sf,score_sf_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=23, max_features=17,\n",
      "                       n_estimators=115, n_jobs=-1, random_state=90)\n",
      "score_sf_re_rf: \n",
      "       fit_time  score_time  test_precision  test_accuracy   test_f1  \\\n",
      "avg  35.943109    0.182465        0.990226       0.998505  0.991753   \n",
      "std   7.966647    0.017226        0.004332       0.000886  0.004891   \n",
      "\n",
      "     test_recall  test_roc_auc  \n",
      "avg     0.993313      0.999650  \n",
      "std     0.007516      0.000704  \n"
     ]
    }
   ],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ train models: RF, GRB, MLP, DT ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# repeat several times for parameters tuning\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-03\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#mm = MinMaxScaler()\n",
    "smo = SMOTE()\n",
    "selector = VarianceThreshold(np.median(data_aftcat_aftmm.var().values))\n",
    "# Random Forest model by parameters tuning\n",
    "model_rf = RandomForestClassifier(criterion='entropy',min_samples_split=2, min_samples_leaf=1, max_features=17, max_depth=23, n_estimators=115,n_jobs=-1,random_state = 90)\n",
    "#model_grb = GradientBoostingClassifier(max_features=3,learning_rate=0.1,n_estimators=130,min_samples_split=100,min_samples_leaf=7,max_depth=15,random_state = 10)\n",
    "\n",
    "\n",
    "# -------------------- model: RF (repeat several times for parameters tuning)-----------------------\n",
    "print(model_rf)\n",
    "score_sf_rf,score_sf_re_rf = train_model(smo, selector, model_rf, data_aftcat_aftmm, data_aftcat_y)\n",
    "print(\"score_sf_re_rf: \\n\", pd.DataFrame(score_sf_re_rf))\n",
    "RF = pd.DataFrame(score_sf_rf['test_f1'],columns = [\"RF\"])\n",
    "#print(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = prediction score for kafka data = = = = = = = =\n",
      "pred_score_sf_re_kafka_rf: \n",
      "       fit_time  score_time  test_precision  test_accuracy   test_f1  \\\n",
      "avg  92.763388    0.245371        0.993116        0.99881  0.993967   \n",
      "std  23.549272    0.044421        0.001546        0.00037  0.001885   \n",
      "\n",
      "     test_recall  test_roc_auc  \n",
      "avg     0.994826      0.999892  \n",
      "std     0.003408      0.000155  \n"
     ]
    }
   ],
   "source": [
    "#  ----------------------------- Prediction method 1: kafka data +cv-----------------------------\n",
    "print(\"= = = = = = = = = prediction score for kafka data = = = = = = = =\")\n",
    "pred_score_sf_kafka_rf,pred_score_sf_re_kafka_rf = pred_kafka(selector, model_rf, testdata_kafka_aftmm, testdata_kafka_label)\n",
    "print(\"pred_score_sf_re_kafka_rf: \\n\", pd.DataFrame(pred_score_sf_re_kafka_rf))\n",
    "pred_RF = pd.DataFrame(pred_score_sf_kafka_rf['test_f1'],columns = [\"pred_RF\"])\n",
    "#print(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c701a3eaa56c792080692be7ed804fc7337106df51979399b9629b6524716ca"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
